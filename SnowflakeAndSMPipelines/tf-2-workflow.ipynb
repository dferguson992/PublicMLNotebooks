{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 2 Complete Project Workflow in Amazon SageMaker\n",
    "### Data Preprocessing -> Code Prototyping -> Automatic Model Tuning -> Deployment\n",
    "    \n",
    "1. [Introduction](#Introduction)\n",
    "2. [SageMaker Processing for dataset transformation](#SageMakerProcessing)\n",
    "3. [SageMaker hosted training](#SageMakerHostedTraining)\n",
    "4. [Automatic Model Tuning](#AutomaticModelTuning)\n",
    "5. [SageMaker hosted endpoint](#SageMakerHostedEndpoint)\n",
    "6. [Workflow Automation with the Step Functions Data Science SDK](#WorkflowAutomation)\n",
    "    1. [Add an IAM policy to your SageMaker role](#IAMPolicy)\n",
    "    2. [Create an execution role for Step Functions](#CreateExecutionRole)\n",
    "    3. [Set up a TrainingPipeline](#TrainingPipeline)\n",
    "    4. [Visualizing the workflow](#VisualizingWorkflow)\n",
    "    5. [Creating and executing the pipeline](#CreatingExecutingPipeline)\n",
    "    6. [Cleanup](#Cleanup)\n",
    "7. [Extensions](#Extensions)\n",
    "\n",
    "\n",
    "### ***Prerequisite:  To run the Local Mode sections of this example, use a SageMaker Notebook Instance; otherwise skip those sections (for example if you're using SageMaker Studio instead).***\n",
    "\n",
    "    \n",
    "## Introduction <a class=\"anchor\" id=\"Introduction\">\n",
    "\n",
    "If you are using TensorFlow 2, you can use the Amazon SageMaker prebuilt TensorFlow 2 container with training scripts similar to those you would use outside SageMaker. This feature is named Script Mode.  Using Script Mode and other SageMaker features, you can build a complete workflow for a TensorFlow 2 project.  This notebook presents such a workflow, including all key steps such as preprocessing data with SageMaker Processing, code prototyping with SageMaker Local Mode training and inference, and production-ready model training and deployment with SageMaker hosted training and inference. Automatic Model Tuning in SageMaker is used to tune the model's hyperparameters.  Additionally, the [AWS Step Functions Data Science SDK](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/readmelink.html) is used to automate the main training and deployment steps for use in a production workflow outside notebooks.    \n",
    "\n",
    "To enable you to run this notebook within a reasonable time (typically less than an hour), this notebook's use case is a straightforward regression task:  predicting house prices based on the well-known Boston Housing dataset. This public dataset contains 13 features regarding housing stock of towns in the Boston area.  Features include average number of rooms, accessibility to radial highways, adjacency to the Charles River, etc.  \n",
    "\n",
    "To begin, we'll import some necessary packages and set up directories for local training and test data.  We'll also set up a SageMaker Session to perform various operations, and specify an Amazon S3 bucket to hold input data and output.  The default bucket used here is created by SageMaker if it doesn't already exist, and named in accordance with the AWS account ID and AWS Region.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() \n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), 'data/train')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "test_dir = os.path.join(os.getcwd(), 'data/test')\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "raw_dir = os.path.join(os.getcwd(), 'data/raw')\n",
    "os.makedirs(raw_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --quiet --upgrade pip\n",
    "!{sys.executable} -m pip install --quiet --upgrade stepfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snowflake import connector\n",
    "from snowflake.connector.pandas_tools import write_pandas, pd_writer\n",
    "# from tensorflow.python.keras.datasets import boston_housing\n",
    "\n",
    "## Phase I: Truncate/Delete the current data in the table\n",
    "# The connector...\n",
    "conn = connector.connect(user=\"\",\n",
    "   password=\"\",\n",
    "   account=\"\",\n",
    "   warehouse=\"\",\n",
    "   database=\"\",\n",
    "   schema=\"\"\n",
    ")\n",
    "\n",
    "# Get Boston Housing Data\n",
    "# (x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# CONVERT INTO PANDAS DATAFRAMES FOR EASY WRITING TO SNOWFLAKE\n",
    "# BOSTON HOUSING ATTRIBUTES\n",
    "#  CRIM     per capita crime rate by town\n",
    "#  ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "#  INDUS    proportion of non-retail business acres per town\n",
    "#  CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "#  NOX      nitric oxides concentration (parts per 10 million)\n",
    "#  RM       average number of rooms per dwelling\n",
    "#  AGE      proportion of owner-occupied units built prior to 1940\n",
    "#  DIS      weighted distances to five Boston employment centres\n",
    "#  RAD      index of accessibility to radial highways\n",
    "#  TAX      full-value property-tax rate per $10,000\n",
    "#  PTRATIO  pupil-teacher ratio by town\n",
    "#  B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "#  LSTAT    % lower status of the population\n",
    "#  MEDV     Median value of owner-occupied homes in $1000's\n",
    "# BOSTON_HOUSING_COLUMNS_X = [\n",
    "#     'CRIM',\n",
    "#     'ZN',\n",
    "#     'INDUS',\n",
    "#     'CHAS',\n",
    "#     'NOX',\n",
    "#     'RM',\n",
    "#     'AGE',\n",
    "#     'DIS',\n",
    "#     'RAD',\n",
    "#     'TAX',\n",
    "#     'PTRATIO',\n",
    "#     'B',\n",
    "#     'LSTAT'\n",
    "# ]\n",
    "# BOSTON_HOUSING_COLUMNS_Y = [\n",
    "#     'MEDV'\n",
    "# ]\n",
    "\n",
    "\n",
    "# x_train_df = pd.DataFrame(x_train, columns = BOSTON_HOUSING_COLUMNS_X)\n",
    "# x_train_df.to_csv('x_train_df.csv', index=False)\n",
    "# # x_train_df.to_sql(\"X_TRAIN\", con=conn, schema=\"BOSTON_HOUSING\", if_exists='replace', index=False, method=pd_writer)\n",
    "                    \n",
    "# x_test_df = pd.DataFrame(x_test, columns = BOSTON_HOUSING_COLUMNS_X)\n",
    "# x_test_df.to_csv('x_test_df.csv', index=False)\n",
    "# # write_pandas(conn, x_test_df, \"X_TEST\")                    \n",
    "                \n",
    "# y_train_df = pd.DataFrame(y_train, columns = BOSTON_HOUSING_COLUMNS_Y)\n",
    "# y_train_df.to_csv('y_train_df.csv', index=False)\n",
    "# # write_pandas(conn, y_train_df, \"Y_TRAIN\")\n",
    "                    \n",
    "# y_test_df = pd.DataFrame(y_test, columns = BOSTON_HOUSING_COLUMNS_Y)\n",
    "# y_test_df.to_csv('y_test_df.csv', index=False)\n",
    "# write_pandas(conn, y_test_df, \"Y_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Processing for dataset transformation <a class=\"anchor\" id=\"SageMakerProcessing\">\n",
    "\n",
    "Next, we'll import the dataset and transform it with SageMaker Processing, which can be used to process terabytes of data in a SageMaker-managed cluster separate from the instance running your notebook server. In a typical SageMaker workflow, notebooks are only used for prototyping and can be run on relatively inexpensive and less powerful instances, while processing, training and model hosting tasks are run on separate, more powerful SageMaker-managed instances.  SageMaker Processing includes off-the-shelf support for Scikit-learn, as well as a Bring Your Own Container option, so it can be used with many different data transformation technologies and tasks.    \n",
    "\n",
    "First we'll load the Boston Housing dataset, save the raw feature data and upload it to Amazon S3 for transformation by SageMaker Processing.  We'll also save the labels for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/raw\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a cursor object.\n",
    "cur = conn.cursor()\n",
    "\n",
    "# READ IN TRAINING AND TEST DATA FOR DEPENDENT & INDEPENDENT VARIABLES\n",
    "sql = \"select * from X_TRAIN\"\n",
    "cur.execute(sql)\n",
    "x_train_df = cur.fetch_pandas_all()\n",
    "\n",
    "sql = \"select * from X_TEST\"\n",
    "cur.execute(sql)\n",
    "x_test_df = cur.fetch_pandas_all()\n",
    "\n",
    "sql = \"select * from Y_TRAIN\"\n",
    "cur.execute(sql)\n",
    "y_train_df = cur.fetch_pandas_all()\n",
    "\n",
    "sql = \"select * from Y_TEST\"\n",
    "cur.execute(sql)\n",
    "y_test_df = cur.fetch_pandas_all()\n",
    "\n",
    "# Close the cursor.\n",
    "cur.close()\n",
    "\n",
    "x_train = pd.DataFrame(x_train_df).to_numpy()\n",
    "x_test = pd.DataFrame(x_test_df).to_numpy()\n",
    "y_train = pd.DataFrame(y_train_df).to_numpy()\n",
    "y_test = pd.DataFrame(y_test_df).to_numpy()\n",
    "\n",
    "\n",
    "np.save(os.path.join(raw_dir, 'xtrain.npy'), x_train)\n",
    "np.save(os.path.join(raw_dir, 'xtest.npy'), x_test)\n",
    "np.save(os.path.join(train_dir, 'ytrain.npy'), y_train)\n",
    "np.save(os.path.join(test_dir, 'ytest.npy'), y_test)\n",
    "s3_prefix = 'tf-2-workflow'\n",
    "rawdata_s3_prefix = '{}/data/raw'.format(s3_prefix)\n",
    "raw_s3 = sess.upload_data(path='./data/raw/', key_prefix=rawdata_s3_prefix)\n",
    "print(raw_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use SageMaker Processing, simply supply a Python data preprocessing script as shown below.  For this example, we're using a SageMaker prebuilt Scikit-learn container, which includes many common functions for processing data.  There are few limitations on what kinds of code and operations you can run, and only a minimal contract:  input and output data must be placed in specified directories.  If this is done, SageMaker Processing automatically loads the input data from S3 and uploads transformed data back to S3 when the job is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    input_files = glob.glob('{}/*.npy'.format('/opt/ml/processing/input'))\n",
    "    print('\\nINPUT FILE LIST: \\n{}\\n'.format(input_files))\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    for file in input_files:\n",
    "        if 'x_' in file:\n",
    "            raw_x = np.load(file)\n",
    "        if 'y_' in file:\n",
    "            raw_y = np.load(file)\n",
    "        else:\n",
    "            raw_y = None\n",
    "            \n",
    "    transformed = scaler.fit_transform(raw_x, raw_y)\n",
    "    for file in input_files:\n",
    "        raw = np.load(file)\n",
    "        transformed = scaler.fit_transform(raw)\n",
    "        if 'train' in file:\n",
    "            output_path = os.path.join('/opt/ml/processing/train', 'xtrain.npy')\n",
    "            np.save(output_path, transformed)\n",
    "            print('SAVED TRANSFORMED TRAINING DATA FILE\\n')\n",
    "        else:\n",
    "            output_path = os.path.join('/opt/ml/processing/test', 'xtest.npy')\n",
    "            np.save(output_path, transformed)\n",
    "            print('SAVED TRANSFORMED TEST DATA FILE\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the SageMaker Processing job, we instantiate a `SKLearnProcessor` object.  This object allows you to specify the instance type to use in the job, as well as how many instances.  Although the Boston Housing dataset is quite small, we'll use two instances to showcase how easy it is to spin up a cluster for SageMaker Processing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=get_execution_role(),\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to run the Processing job.  To enable distributing the data files equally among the instances, we specify the `ShardedByS3Key` distribution type in the `ProcessingInput` object.  This ensures that if we have `n` instances, each instance will receive `1/n` files from the specified S3 bucket.  It may take around 3 minutes for the following code cell to run, mainly to set up the cluster.  At the end of the job, the cluster automatically will be torn down by SageMaker.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  tf-2-workflow-11-16-29-29\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/raw', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-29-29/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".........................\u001b[35m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[35mINPUT FILE LIST: \u001b[0m\n",
      "\u001b[35m['/opt/ml/processing/input/xtrain.npy', '/opt/ml/processing/input/x_train.npy']\u001b[0m\n",
      "\u001b[35mSAVED TRANSFORMED TRAINING DATA FILE\u001b[0m\n",
      "\u001b[35mSAVED TRANSFORMED TRAINING DATA FILE\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mINPUT FILE LIST: \u001b[0m\n",
      "\u001b[34m['/opt/ml/processing/input/x_test.npy', '/opt/ml/processing/input/xtest.npy']\u001b[0m\n",
      "\u001b[34mSAVED TRANSFORMED TEST DATA FILE\u001b[0m\n",
      "\u001b[34mSAVED TRANSFORMED TEST DATA FILE\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from time import gmtime, strftime \n",
    "\n",
    "processing_job_name = \"tf-2-workflow-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "output_destination = 's3://{}/{}/data'.format(bucket, s3_prefix)\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "                      job_name=processing_job_name,\n",
    "                      inputs=[ProcessingInput(\n",
    "                            source=raw_s3,\n",
    "                            destination='/opt/ml/processing/input',\n",
    "                            s3_data_distribution_type='ShardedByS3Key')],\n",
    "                      outputs=[ProcessingOutput(output_name='train',\n",
    "                                                destination='{}/train'.format(output_destination),\n",
    "                                                source='/opt/ml/processing/train'),\n",
    "                               ProcessingOutput(output_name='test',\n",
    "                                                destination='{}/test'.format(output_destination),\n",
    "                                                source='/opt/ml/processing/test')])\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the log output of the SageMaker Processing job above, you should be able to see logs in two different colors for the two different instances, and that each instance received different files.  Without the `ShardedByS3Key` distribution type, each instance would have received a copy of **all** files.  By spreading the data equally among `n` instances, you should receive a speedup by approximately a factor of `n` for most stateless data transformations.  After saving the job results locally, we'll move on to prototyping training and inference code with Local Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train/xtrain.npy to data/train/xtrain.npy\n",
      "download: s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test/xtest.npy to data/test/xtest.npy\n"
     ]
    }
   ],
   "source": [
    "train_in_s3 = '{}/train/xtrain.npy'.format(output_destination)\n",
    "test_in_s3 = '{}/test/xtest.npy'.format(output_destination)\n",
    "!aws s3 cp {train_in_s3} ./data/train/xtrain.npy\n",
    "!aws s3 cp {test_in_s3} ./data/test/xtest.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SageMaker hosted training <a class=\"anchor\" id=\"SageMakerHostedTraining\">\n",
    "\n",
    "Now that we've confirmed our code is working locally, we can move on to use SageMaker's hosted training functionality. Hosted training is preferred for doing actual training, especially large-scale, distributed training.  Unlike Local Mode training, for hosted training the actual training itself occurs not on the notebook instance, but on a separate cluster of machines managed by SageMaker.  Before starting hosted training, the data must be in S3, or an EFS or FSx for Lustre file system. We'll upload to S3 now, and confirm the upload was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 'tf-2-workflow'\n",
    "\n",
    "traindata_s3_prefix = '{}/data/train'.format(s3_prefix)\n",
    "testdata_s3_prefix = '{}/data/test'.format(s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 's3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train', 'test': 's3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test'}\n"
     ]
    }
   ],
   "source": [
    "train_s3 = sess.upload_data(path='./data/train/', key_prefix=traindata_s3_prefix)\n",
    "test_s3 = sess.upload_data(path='./data/test/', key_prefix=testdata_s3_prefix)\n",
    "\n",
    "inputs = {'train':train_s3, 'test': test_s3}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to set up an Estimator object for hosted training. It is similar to the Local Mode Estimator, except the `train_instance_type` has been set to a SageMaker ML instance type instead of `local` for Local Mode. Also, since we know our code is working now, we'll train for a larger number of epochs with the expectation that model training will converge to an improved, lower validation loss.\n",
    "\n",
    "With these two changes, we simply call `fit` to start the actual hosted training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "train_instance_type = 'ml.c5.xlarge'\n",
    "hyperparameters = {'epochs': 30, 'batch_size': 128, 'learning_rate': 0.01}\n",
    "\n",
    "git_config = {'repo': 'https://github.com/aws-samples/amazon-sagemaker-script-mode', \n",
    "              'branch': 'master'}\n",
    "\n",
    "model_dir = '/opt/ml/model'\n",
    "estimator = TensorFlow(git_config=git_config,\n",
    "                       source_dir='tf-2-workflow/train_model',\n",
    "                       entry_point='train.py',\n",
    "                       model_dir=model_dir,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=1,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name='tf-2-workflow',\n",
    "                       framework_version='2.2',\n",
    "                       py_version='py37',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting the hosted training job with the `fit` method call below, you should observe the training converge over the longer number of epochs to a validation loss that is considerably lower than that which was achieved in the shorter Local Mode training job.  Can we do better? We'll look into a way to do so in the **Automatic Model Tuning** section below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-11 16:35:52 Starting - Starting the training job...\n",
      "2021-11-11 16:36:15 Starting - Launching requested ML instancesProfilerReport-1636648551: InProgress\n",
      "......\n",
      "2021-11-11 16:37:15 Starting - Preparing the instances for training.........\n",
      "2021-11-11 16:38:36 Downloading - Downloading input data......\n",
      "2021-11-11 16:39:42 Training - Downloading the training image..\u001b[34m2021-11-11 16:39:58.089037: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-11 16:39:58.095071: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:106] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-11-11 16:39:58.232351: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:01,889 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:01,896 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:02,377 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:02,392 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:02,409 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:02,418 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"epochs\": 30,\n",
      "        \"learning_rate\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-2-workflow-2021-11-11-16-35-51-607\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-2021-11-11-16-35-51-607/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":128,\"epochs\":30,\"learning_rate\":0.01,\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-329542461890/tf-2-workflow-2021-11-11-16-35-51-607/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":30,\"learning_rate\":0.01,\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-2-workflow-2021-11-11-16-35-51-607\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-2021-11-11-16-35-51-607/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"30\",\"--learning_rate\",\"0.01\",\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=30\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 train.py --batch_size 128 --epochs 30 --learning_rate 0.01 --model_dir /opt/ml/model\u001b[0m\n",
      "\u001b[34mTraining data location: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mTest data location: /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mx train (404, 13) y train (404,)\u001b[0m\n",
      "\u001b[34mx test (102, 13) y test (102,)\u001b[0m\n",
      "\u001b[34m/cpu:0\u001b[0m\n",
      "\u001b[34mbatch_size = 128, epochs = 30, learning rate = 0.01\u001b[0m\n",
      "\u001b[34m[2021-11-11 16:40:04.435 ip-10-0-198-10.ec2.internal:22 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-11-11 16:40:04.436 ip-10-0-198-10.ec2.internal:22 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-11-11 16:40:04.436 ip-10-0-198-10.ec2.internal:22 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-11-11 16:40:04.436 ip-10-0-198-10.ec2.internal:22 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mEpoch 1/30\u001b[0m\n",
      "\u001b[34m[2021-11-11 16:40:04.599 ip-10-0-198-10.ec2.internal:22 INFO hook.py:398] Monitoring the collections: sm_metrics, losses, metrics\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 588.7880#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 74ms/step - loss: 520.3248 - val_loss: 407.6950 - batch: 0.0000e+00\u001b[0m\n",
      "\u001b[34mEpoch 2/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 352.8651#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 14ms/step - loss: 338.0840 - val_loss: 229.9247 - batch: 1.0000\u001b[0m\n",
      "\u001b[34mEpoch 3/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 189.5682#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 14ms/step - loss: 184.6116 - val_loss: 122.3275 - batch: 2.0000\u001b[0m\n",
      "\u001b[34mEpoch 4/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 98.8224#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 102.2957 - val_loss: 80.5858 - batch: 3.0000\u001b[0m\n",
      "\u001b[34mEpoch 5/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 79.4586#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 16ms/step - loss: 73.4583 - val_loss: 62.4776 - batch: 4.0000\u001b[0m\n",
      "\u001b[34mEpoch 6/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 45.4919#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 11ms/step - loss: 61.0249 - val_loss: 54.2793 - batch: 5.0000\u001b[0m\n",
      "\u001b[34mEpoch 7/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 61.1519#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 14ms/step - loss: 55.3296 - val_loss: 49.7151 - batch: 6.0000\u001b[0m\n",
      "\u001b[34mEpoch 8/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 37.5771#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 14ms/step - loss: 51.8108 - val_loss: 46.5967 - batch: 7.0000\u001b[0m\n",
      "\u001b[34mEpoch 9/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 51.4765#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 10ms/step - loss: 49.3475 - val_loss: 44.4709 - batch: 8.0000\u001b[0m\n",
      "\u001b[34mEpoch 10/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 48.2760#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 11ms/step - loss: 47.2798 - val_loss: 42.2346 - batch: 9.0000\u001b[0m\n",
      "\u001b[34mEpoch 11/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 56.7472#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 45.3999 - val_loss: 40.3685 - batch: 10.0000\u001b[0m\n",
      "\u001b[34mEpoch 12/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 39.7393#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 43.3454 - val_loss: 38.1498 - batch: 11.0000\u001b[0m\n",
      "\u001b[34mEpoch 13/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 40.9393#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 10ms/step - loss: 41.2065 - val_loss: 37.2621 - batch: 12.0000\u001b[0m\n",
      "\u001b[34mEpoch 14/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 40.4939#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 10ms/step - loss: 39.5341 - val_loss: 36.9093 - batch: 13.0000\u001b[0m\n",
      "\u001b[34mEpoch 15/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 39.2767#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 10ms/step - loss: 38.0628 - val_loss: 34.8147 - batch: 14.0000\u001b[0m\n",
      "\u001b[34mEpoch 16/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 33.0257#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 36.2818 - val_loss: 33.1396 - batch: 15.0000\u001b[0m\n",
      "\u001b[34mEpoch 17/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 34.8221#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 12ms/step - loss: 34.6863 - val_loss: 31.6187 - batch: 16.0000\u001b[0m\n",
      "\u001b[34mEpoch 18/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 36.1359#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 13ms/step - loss: 33.1718 - val_loss: 30.6745 - batch: 17.0000\u001b[0m\n",
      "\u001b[34mEpoch 19/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 31.8069#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 31.4301 - val_loss: 30.7220 - batch: 18.0000\u001b[0m\n",
      "\u001b[34mEpoch 20/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 24.7460#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 30.5672 - val_loss: 29.4021 - batch: 19.0000\u001b[0m\n",
      "\u001b[34mEpoch 21/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 40.6277#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 28.6272 - val_loss: 29.8679 - batch: 20.0000\u001b[0m\n",
      "\u001b[34mEpoch 22/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 25.1108#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 27.6198 - val_loss: 28.2838 - batch: 21.0000\u001b[0m\n",
      "\u001b[34mEpoch 23/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 36.1147#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 26.2556 - val_loss: 27.9075 - batch: 22.0000\u001b[0m\n",
      "\u001b[34mEpoch 24/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 43.9491#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 26.8635 - val_loss: 27.7893 - batch: 23.0000\u001b[0m\n",
      "\u001b[34mEpoch 25/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 28.4094#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 24.1337 - val_loss: 25.8348 - batch: 24.0000\u001b[0m\n",
      "\u001b[34mEpoch 26/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 33.7954#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 24.3421 - val_loss: 31.3424 - batch: 25.0000\u001b[0m\n",
      "\u001b[34mEpoch 27/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 32.5022#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 30.7295 - val_loss: 25.1211 - batch: 26.0000\u001b[0m\n",
      "\u001b[34mEpoch 28/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 14.3683#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 21.8442 - val_loss: 24.0729 - batch: 27.0000\u001b[0m\n",
      "\u001b[34mEpoch 29/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 19.2663#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 8ms/step - loss: 21.0261 - val_loss: 23.9673 - batch: 28.0000\u001b[0m\n",
      "\u001b[34mEpoch 30/30\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 22.5522#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 20.6205 - val_loss: 23.7034 - batch: 29.0000\u001b[0m\n",
      "\u001b[34m1/1 - 0s - loss: 23.7034\u001b[0m\n",
      "\u001b[34mTest MSE : 23.703397750854492\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:02.690564: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:02.690674: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:106] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:02.709694: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:06.845390: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34m2021-11-11 16:40:07,450 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-11-11 16:40:16 Uploading - Uploading generated training model\n",
      "2021-11-11 16:40:16 Completed - Training job completed\n",
      "Training seconds: 105\n",
      "Billable seconds: 105\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Local Mode training, hosted training produces a model saved in S3 that we can retrieve.  This is an example of the modularity of SageMaker: having trained the model in SageMaker, you can now take the model out of SageMaker and run it anywhere else.  Alternatively, you can deploy the model into a production-ready environment using SageMaker's hosted endpoints functionality, as shown in the **SageMaker hosted endpoint** section below.\n",
    "\n",
    "Retrieving the model from S3 is very easy:  the hosted training estimator you created above stores a reference to the model's location in S3.  You simply copy the model from S3 using the estimator's `model_data` property and unzip it to inspect the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 10.2 KiB/10.2 KiB (102.0 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-1-329542461890/tf-2-workflow-2021-11-11-16-35-51-607/output/model.tar.gz to model/model.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {estimator.model_data} ./model/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unzipped archive should include the assets required by TensorFlow Serving to load the model and serve it, including a .pb file:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/\r\n",
      "1/variables/\r\n",
      "1/variables/variables.index\r\n",
      "1/variables/variables.data-00000-of-00001\r\n",
      "1/saved_model.pb\r\n",
      "1/assets/\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf ./model/model.tar.gz -C ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Model Tuning <a class=\"anchor\" id=\"AutomaticModelTuning\">\n",
    "\n",
    "So far we have simply run one Local Mode training job and one Hosted Training job without any real attempt to tune hyperparameters to produce a better model, other than increasing the number of epochs.  Selecting the right hyperparameter values to train your model can be difficult, and typically is very time consuming if done manually. The right combination of hyperparameters is dependent on your data and algorithm; some algorithms have many different hyperparameters that can be tweaked; some are very sensitive to the hyperparameter values selected; and most have a non-linear relationship between model fit and hyperparameter values.  SageMaker Automatic Model Tuning helps automate the hyperparameter tuning process:  it runs multiple training jobs with different hyperparameter combinations to find the set with the best model performance.\n",
    "\n",
    "We begin by specifying the hyperparameters we wish to tune, and the range of values over which to tune each one.  We also must specify an objective metric to be optimized:  in this use case, we'd like to minimize the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "  'learning_rate': ContinuousParameter(0.001, 0.2, scaling_type=\"Logarithmic\"),\n",
    "  'epochs': IntegerParameter(10, 50),\n",
    "  'batch_size': IntegerParameter(64, 256),\n",
    "}\n",
    "\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': ' loss: ([0-9\\\\.]+)'},\n",
    "                     {'Name': 'val_loss',\n",
    "                       'Regex': ' val_loss: ([0-9\\\\.]+)'}]\n",
    "\n",
    "objective_metric_name = 'val_loss'\n",
    "objective_type = 'Minimize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we specify a HyperparameterTuner object that takes the above definitions as parameters.  Each tuning job must be given a budget:  a maximum number of training jobs.  A tuning job will complete after that many training jobs have been executed.  \n",
    "\n",
    "We also can specify how much parallelism to employ, in this case five jobs, meaning that the tuning job will complete after three series of five jobs in parallel have completed.  For the default Bayesian Optimization tuning strategy used here, the tuning search is informed by the results of previous groups of training jobs, so we don't run all of the jobs in parallel, but rather divide the jobs into groups of parallel jobs.  There is a trade-off: using more parallel jobs will finish tuning sooner, but likely will sacrifice tuning search accuracy. \n",
    "\n",
    "Now we can launch a hyperparameter tuning job by calling the `fit` method of the HyperparameterTuner object.  The tuning job may take around 10 minutes to finish.  While you're waiting, the status of the tuning job, including metadata and results for invidual training jobs within the tuning job, can be checked in the SageMaker console in the **Hyperparameter tuning jobs** panel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=15,\n",
    "                            max_parallel_jobs=5,\n",
    "                            objective_type=objective_type)\n",
    "\n",
    "tuning_job_name = \"tf-2-workflow-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "tuner.fit(inputs, job_name=tuning_job_name)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tuning job is finished, we can use the `HyperparameterTuningJobAnalytics` object from the SageMaker Python SDK to list the top 5 tuning jobs with the best performance. Although the results vary from tuning job to tuning job, the best validation loss from the tuning job (under the FinalObjectiveValue column) likely will be substantially lower than the validation loss from the hosted training job above, where we did not perform any tuning other than manually increasing the number of epochs once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.148746</td>\n",
       "      <td>tf-2-workflow-11-16-42-53-015-26d5c15b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>17.760500</td>\n",
       "      <td>2021-11-11 16:54:20+00:00</td>\n",
       "      <td>2021-11-11 16:55:43+00:00</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>151.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.027827</td>\n",
       "      <td>tf-2-workflow-11-16-42-53-002-ee17fda9</td>\n",
       "      <td>Completed</td>\n",
       "      <td>17.974899</td>\n",
       "      <td>2021-11-11 16:45:23+00:00</td>\n",
       "      <td>2021-11-11 16:46:20+00:00</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.023999</td>\n",
       "      <td>tf-2-workflow-11-16-42-53-013-a78ebf91</td>\n",
       "      <td>Completed</td>\n",
       "      <td>19.737499</td>\n",
       "      <td>2021-11-11 16:53:44+00:00</td>\n",
       "      <td>2021-11-11 16:54:47+00:00</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>tf-2-workflow-11-16-42-53-012-ebce8b69</td>\n",
       "      <td>Completed</td>\n",
       "      <td>20.578300</td>\n",
       "      <td>2021-11-11 16:53:47+00:00</td>\n",
       "      <td>2021-11-11 16:54:47+00:00</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>123.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.027616</td>\n",
       "      <td>tf-2-workflow-11-16-42-53-008-46314781</td>\n",
       "      <td>Completed</td>\n",
       "      <td>21.204901</td>\n",
       "      <td>2021-11-11 16:49:33+00:00</td>\n",
       "      <td>2021-11-11 16:51:09+00:00</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size  epochs  learning_rate                         TrainingJobName  \\\n",
       "0        229.0    41.0       0.148746  tf-2-workflow-11-16-42-53-015-26d5c15b   \n",
       "13       151.0    26.0       0.027827  tf-2-workflow-11-16-42-53-002-ee17fda9   \n",
       "2        137.0    41.0       0.023999  tf-2-workflow-11-16-42-53-013-a78ebf91   \n",
       "3        145.0    48.0       0.058072  tf-2-workflow-11-16-42-53-012-ebce8b69   \n",
       "7        123.0    36.0       0.027616  tf-2-workflow-11-16-42-53-008-46314781   \n",
       "\n",
       "   TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0          Completed            17.760500 2021-11-11 16:54:20+00:00   \n",
       "13         Completed            17.974899 2021-11-11 16:45:23+00:00   \n",
       "2          Completed            19.737499 2021-11-11 16:53:44+00:00   \n",
       "3          Completed            20.578300 2021-11-11 16:53:47+00:00   \n",
       "7          Completed            21.204901 2021-11-11 16:49:33+00:00   \n",
       "\n",
       "             TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0  2021-11-11 16:55:43+00:00                        83.0  \n",
       "13 2021-11-11 16:46:20+00:00                        57.0  \n",
       "2  2021-11-11 16:54:47+00:00                        63.0  \n",
       "3  2021-11-11 16:54:47+00:00                        60.0  \n",
       "7  2021-11-11 16:51:09+00:00                        96.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total training time and training jobs status can be checked with the following lines of code. Because automatic early stopping is by default off, all the training jobs should be completed normally.  For an example of a more in-depth analysis of a tuning job, see the SageMaker official sample [HPO_Analyze_TuningJob_Results.ipynb](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total training time is 0.33 hours\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Completed    15\n",
       "Name: TrainingJobStatus, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = tuner_metrics.dataframe()['TrainingElapsedTimeSeconds'].sum() / 3600\n",
    "print(\"The total training time is {:.2f} hours\".format(total_time))\n",
    "tuner_metrics.dataframe()['TrainingJobStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SageMaker hosted endpoint <a class=\"anchor\" id=\"SageMakerHostedEndpoint\">\n",
    "\n",
    "Assuming the best model from the tuning job is better than the model produced by the individual Hosted Training job above, we could now easily deploy that model to production.  A convenient option is to use a SageMaker hosted endpoint, which serves real time predictions from the trained model (Batch Transform jobs also are available for asynchronous, offline predictions on large datasets). The endpoint will retrieve the TensorFlow SavedModel created during training and deploy it within a SageMaker TensorFlow Serving container. This all can be accomplished with one line of code.  \n",
    "\n",
    "More specifically, by calling the `deploy` method of the HyperparameterTuner object we instantiated above, we can directly deploy the best model from the tuning job to a SageMaker hosted endpoint.  It will take several minutes longer to deploy the model to the hosted endpoint compared to the Local Mode endpoint, which is more useful for fast prototyping of inference code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-11-11 16:55:43 Starting - Preparing the instances for training\n",
      "2021-11-11 16:55:43 Downloading - Downloading input data\n",
      "2021-11-11 16:55:43 Training - Training image download completed. Training in progress.\n",
      "2021-11-11 16:55:43 Uploading - Uploading generated training model\n",
      "2021-11-11 16:55:43 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "tuning_predictor = tuner.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the predictions generated by this endpoint with those generated locally by the Local Mode endpoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \t[23.4 32.1 32.1 32.1 32.1 32.1 32.1 32.1 32.1 32.1]\n",
      "target values: \t[[ 7.2]\n",
      " [18.8]\n",
      " [19. ]\n",
      " [27. ]\n",
      " [22.2]\n",
      " [24.5]\n",
      " [31.2]\n",
      " [22.9]\n",
      " [20.5]\n",
      " [23.2]]\n"
     ]
    }
   ],
   "source": [
    "results = tuning_predictor.predict(x_test[:10])['predictions'] \n",
    "flat_list = [float('%.1f'%(item)) for sublist in results for item in sublist]\n",
    "print('predictions: \\t{}'.format(np.array(flat_list)))\n",
    "print('target values: \\t{}'.format(y_test[:10].round(decimals=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid billing charges from stray resources, you can delete the prediction endpoint to release its associated instance(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Automation with the AWS Step Functions Data Science SDK <a class=\"anchor\" id=\"WorkflowAutomation\">\n",
    "\n",
    "In the previous parts of this notebook, we prototyped various steps of a TensorFlow project within the notebook itself.  Notebooks are great for prototyping, but generally are  not used in production-ready machine learning pipelines.  For example, a simple pipeline in SageMaker includes the following steps:  \n",
    "\n",
    "1. Training the model.\n",
    "2. Creating a SageMaker Model object that wraps the model artifact for serving.\n",
    "3. Creating a SageMaker Endpoint Configuration specifying how the model should be served (e.g. hardware type and amount).\n",
    "4. Deploying the trained model to the configured SageMaker Endpoint.  \n",
    "\n",
    "The AWS Step Functions Data Science SDK automates the process of creating and running these kinds of workflows using AWS Step Functions and SageMaker.  It does this by allowing you to create workflows using short, simple Python scripts that define workflow steps and chain them together.  Under the hood, all the workflow steps are coordinated by AWS Step Functions without any need for you to manage the underlying infrastructure.  \n",
    "\n",
    "To begin, install the Step Functions Data Science SDK:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --quiet --upgrade stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add an IAM policy to your SageMaker role <a class=\"anchor\" id=\"IAMPolicy\">\n",
    "\n",
    "**If you are running this notebook on an Amazon SageMaker notebook instance**, the IAM role assumed by your notebook instance needs permission to create and run workflows in AWS Step Functions. To provide this permission to the role, do the following.\n",
    "\n",
    "1. Open the Amazon [SageMaker console](https://console.aws.amazon.com/sagemaker/). \n",
    "2. Select **Notebook instances** and choose the name of your notebook instance\n",
    "3. Under **Permissions and encryption** select the role ARN to view the role on the IAM console\n",
    "4. Choose **Attach policies** and search for `AWSStepFunctionsFullAccess`.\n",
    "5. Select the check box next to `AWSStepFunctionsFullAccess` and choose **Attach policy**\n",
    "\n",
    "If you are running this notebook in a local environment, the SDK will use your configured AWS CLI configuration. For more information, see [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).\n",
    "\n",
    "\n",
    "### Create an execution role for Step Functions <a class=\"anchor\" id=\"CreateExecutionRole\">\n",
    "\n",
    "You also need to create an execution role for Step Functions to enable that service to access SageMaker and other service functionality.\n",
    "\n",
    "1. Go to the [IAM console](https://console.aws.amazon.com/iam/)\n",
    "2. Select **Roles** and then **Create role**.\n",
    "3. Under **Choose the service that will use this role** select **Step Functions**\n",
    "4. Choose **Next** until you can enter a **Role name**\n",
    "5. Enter a name such as `StepFunctionsWorkflowExecutionRole` and then select **Create role**\n",
    "\n",
    "\n",
    "Select your newly create role and attach a policy to it. The following steps attach a policy that provides full access to Step Functions, however as a good practice you should only provide access to the resources you need.  \n",
    "\n",
    "1. Under the **Permissions** tab, click **Add inline policy**\n",
    "2. Enter the following in the **JSON** tab\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:CreateTransformJob\",\n",
    "                \"sagemaker:DescribeTransformJob\",\n",
    "                \"sagemaker:StopTransformJob\",\n",
    "                \"sagemaker:CreateTrainingJob\",\n",
    "                \"sagemaker:DescribeTrainingJob\",\n",
    "                \"sagemaker:StopTrainingJob\",\n",
    "                \"sagemaker:CreateHyperParameterTuningJob\",\n",
    "                \"sagemaker:DescribeHyperParameterTuningJob\",\n",
    "                \"sagemaker:StopHyperParameterTuningJob\",\n",
    "                \"sagemaker:CreateModel\",\n",
    "                \"sagemaker:CreateEndpointConfig\",\n",
    "                \"sagemaker:CreateEndpoint\",\n",
    "                \"sagemaker:DeleteEndpointConfig\",\n",
    "                \"sagemaker:DeleteEndpoint\",\n",
    "                \"sagemaker:UpdateEndpoint\",\n",
    "                \"sagemaker:ListTags\",\n",
    "                \"lambda:InvokeFunction\",\n",
    "                \"sqs:SendMessage\",\n",
    "                \"sns:Publish\",\n",
    "                \"ecs:RunTask\",\n",
    "                \"ecs:StopTask\",\n",
    "                \"ecs:DescribeTasks\",\n",
    "                \"dynamodb:GetItem\",\n",
    "                \"dynamodb:PutItem\",\n",
    "                \"dynamodb:UpdateItem\",\n",
    "                \"dynamodb:DeleteItem\",\n",
    "                \"batch:SubmitJob\",\n",
    "                \"batch:DescribeJobs\",\n",
    "                \"batch:TerminateJob\",\n",
    "                \"glue:StartJobRun\",\n",
    "                \"glue:GetJobRun\",\n",
    "                \"glue:GetJobRuns\",\n",
    "                \"glue:BatchStopJobRun\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"events:PutTargets\",\n",
    "                \"events:PutRule\",\n",
    "                \"events:DescribeRule\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTrainingJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTransformJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTuningJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForECSTaskRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForBatchJobsRule\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "3. Choose **Review policy** and give the policy a name such as `StepFunctionsWorkflowExecutionPolicy`\n",
    "4. Choose **Create policy**. You will be redirected to the details page for the role.\n",
    "5. Copy the **Role ARN** at the top of the **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a TrainingPipeline <a class=\"anchor\" id=\"TrainingPipeline\">\n",
    "\n",
    "Although the AWS Step Functions Data Science SDK provides various primitives to build up pipelines from scratch, it also provides prebuilt templates for common workflows, including a [TrainingPipeline](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/pipelines.html#stepfunctions.template.pipeline.train.TrainingPipeline) object to simplify creation of a basic pipeline that includes model training and deployment. \n",
    "\n",
    "The following code cell configures a  `pipeline` object with the necessary parameters to define such a simple pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-11-11 16:55:43 Starting - Preparing the instances for training\n",
      "2021-11-11 16:55:43 Downloading - Downloading input data\n",
      "2021-11-11 16:55:43 Training - Training image download completed. Training in progress.\n",
      "2021-11-11 16:55:43 Uploading - Uploading generated training model\n",
      "2021-11-11 16:55:43 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "import stepfunctions\n",
    "\n",
    "from stepfunctions.template.pipeline import TrainingPipeline\n",
    "\n",
    "# paste the StepFunctionsWorkflowExecutionRole ARN from above\n",
    "workflow_execution_role = \"\"\n",
    "\n",
    "# get best tuned estimator\n",
    "optimized_estimator = tuner.best_estimator()\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    estimator=optimized_estimator,\n",
    "    role=workflow_execution_role,\n",
    "    inputs=inputs,\n",
    "    s3_bucket=bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the workflow <a class=\"anchor\" id=\"VisualizingWorkflow\">\n",
    "\n",
    "You can now view the workflow definition, and visualize it as a graph. This workflow and graph represent your training pipeline from starting a training job to deploying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"StartAt\": \"Training\",\n",
      "    \"States\": {\n",
      "        \"Training\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\",\n",
      "            \"Parameters\": {\n",
      "                \"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\",\n",
      "                \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\",\n",
      "                \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\",\n",
      "                \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\",\n",
      "                \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\",\n",
      "                \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\",\n",
      "                \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\",\n",
      "                \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\",\n",
      "                \"Tags.$\": \"$$.Execution.Input['Training'].Tags\",\n",
      "                \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Create Model\"\n",
      "        },\n",
      "        \"Create Model\": {\n",
      "            \"Parameters\": {\n",
      "                \"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\",\n",
      "                \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\",\n",
      "                \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"\n",
      "            },\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createModel\",\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Configure Endpoint\"\n",
      "        },\n",
      "        \"Configure Endpoint\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\",\n",
      "                \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Deploy\"\n",
      "        },\n",
      "        \"Deploy\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\",\n",
      "                \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"End\": true\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.workflow.definition.to_json(pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-375\" class=\"workflowgraph\">\n",
       "    \n",
       "    <svg></svg>\n",
       "    \n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var element = document.getElementById('graph-375')\n",
       "\n",
       "    var options = {\n",
       "        width: parseFloat(getComputedStyle(element, null).width.replace(\"px\", \"\")),\n",
       "        height: 600,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Training\", \"States\": {\"Training\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\", \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\", \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\", \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\", \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\", \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\", \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\", \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\", \"Tags.$\": \"$$.Execution.Input['Training'].Tags\", \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"}, \"Type\": \"Task\", \"Next\": \"Create Model\"}, \"Create Model\": {\"Parameters\": {\"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\", \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\", \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Configure Endpoint\"}, \"Configure Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\", \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"}, \"Type\": \"Task\", \"Next\": \"Deploy\"}, \"Deploy\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\", \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-375';\n",
       "\n",
       "    var graph = new sfn.StateMachineGraph(definition, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.render_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and executing the pipeline <a class=\"anchor\" id=\"CreatingExecutingPipeline\">\n",
    "\n",
    "Before the workflow can be run for the first time, the pipeline must be created using the `create` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:states:us-east-1:329542461890:stateMachine:training-pipeline-2021-11-11-16-58-07'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the workflow can be started by invoking the pipeline's `execute` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `list_executions` method to list all executions for the workflow you created, including the one we just started.  After a pipeline is created, it can be executed as many times as needed, for example on a schedule for retraining on new data.  (For purposes of this notebook just execute the workflow one time to save resources.)  The output will include a list you can click through to access a view of the execution in the AWS Step Functions console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        \n",
       "    .table-widget {\n",
       "        width: 100%;\n",
       "        font-size: 14px;\n",
       "        line-height: 28px;\n",
       "        color: #545b64;\n",
       "        border-spacing: 0;\n",
       "        background-color: #fff;\n",
       "        border-color: grey;\n",
       "        background: #fafafa;\n",
       "    }\n",
       "\n",
       "    .table-widget thead th {\n",
       "        text-align: left !important;\n",
       "        color: #879596;\n",
       "        padding: 0.3em 2em;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        min-height: 4rem;\n",
       "        line-height: 28px;\n",
       "    }\n",
       "\n",
       "    .table-widget thead th:first-of-type {\n",
       "    }\n",
       "\n",
       "    .table-widget td {\n",
       "        overflow-wrap: break-word;\n",
       "        padding: 0.4em 2em;\n",
       "        line-height: 28px;\n",
       "        text-align: left !important;\n",
       "        background: #fff;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        border-top: 1px solid transparent;\n",
       "    }\n",
       "\n",
       "    .table-widget td:before {\n",
       "        content: \"\";\n",
       "        height: 3rem;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        cursor: pointer;\n",
       "        text-decoration: none !important;\n",
       "        color: #007dbc;\n",
       "    }\n",
       "\n",
       "    a:hover {\n",
       "        text-decoration: underline !important;\n",
       "    }\n",
       "\n",
       "    a.disabled {\n",
       "        color: black;\n",
       "        cursor: default;\n",
       "        pointer-events: none;\n",
       "    }\n",
       "\n",
       "    .hide {\n",
       "        display: none;\n",
       "    }\n",
       "\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "\n",
       "        \n",
       "    * {\n",
       "        box-sizing: border-box;\n",
       "    }\n",
       "\n",
       "    .table-widget {\n",
       "        min-width: 100%;\n",
       "        font-size: 14px;\n",
       "        line-height: 28px;\n",
       "        color: #545b64;\n",
       "        border-spacing: 0;\n",
       "        background-color: #fff;\n",
       "        border-color: grey;\n",
       "        background: #fafafa;\n",
       "    }\n",
       "\n",
       "    .table-widget thead th {\n",
       "        text-align: left !important;\n",
       "        color: #879596;\n",
       "        padding: 0.3em 2em;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        min-height: 4rem;\n",
       "        line-height: 28px;\n",
       "    }\n",
       "\n",
       "    .table-widget td {\n",
       "        /* padding: 24px 18px; */\n",
       "        padding: 0.4em 2em;\n",
       "        line-height: 28px;\n",
       "        text-align: left !important;\n",
       "        background: #fff;\n",
       "        border-bottom: 1px solid #eaeded;\n",
       "        border-top: 1px solid transparent;\n",
       "    }\n",
       "\n",
       "    .table-widget td:before {\n",
       "        content: \"\";\n",
       "        height: 3rem;\n",
       "    }\n",
       "\n",
       "    .table-widget .clickable-cell {\n",
       "        cursor: pointer;\n",
       "    }\n",
       "\n",
       "    .hide {\n",
       "        display: none;\n",
       "    }\n",
       "\n",
       "    .triangle-right {\n",
       "        width: 0;\n",
       "        height: 0;\n",
       "        border-top: 5px solid transparent;\n",
       "        border-left: 8px solid #545b64;\n",
       "        border-bottom: 5px solid transparent;\n",
       "        margin-right: 5px;\n",
       "    }\n",
       "\n",
       "    a.awsui {\n",
       "        text-decoration: none !important;\n",
       "        color: #007dbc;\n",
       "    }\n",
       "\n",
       "    a.awsui:hover {\n",
       "        text-decoration: underline !important;\n",
       "    }\n",
       "\n",
       "    </style>\n",
       "    <table class=\"table-widget\">\n",
       "        <thead>\n",
       "            <tr>\n",
       "                <th>Name</th>\n",
       "                <th>Status</th>\n",
       "                <th>Started</th>\n",
       "                <th>End Time</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "    <tr class=\"awsui-table-row\">\n",
       "        <td>\n",
       "            <a href=\"https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:329542461890:execution:training-pipeline-2021-11-11-16-58-07:training-pipeline-2021-11-11-17-00-59\" target=\"_blank\" class=\"awsui\">training-pipeline-2021-11-11-17-00-59</a>\n",
       "        </td>\n",
       "        <td>RUNNING</td>\n",
       "        <td>Nov 11, 2021 05:00:59.590 PM</td>\n",
       "        <td>-</td>\n",
       "    </tr>\n",
       "\n",
       "        </tbody>\n",
       "    </table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.workflow.list_executions(html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the workflow is running, you can check workflow progress inside this notebook with the `render_progress` method.  This generates a snapshot of the current state of your workflow as it executes. This is a static image. Run the cell again to check progress while the workflow is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-131\" class=\"workflowgraph\">\n",
       "    \n",
       "    <style>\n",
       "        .graph-legend ul {\n",
       "            list-style-type: none;\n",
       "            padding: 10px;\n",
       "            padding-left: 0;\n",
       "            margin: 0;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            background: transparent;\n",
       "        }\n",
       "\n",
       "        .graph-legend li {\n",
       "            margin-left: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend li > div {\n",
       "            width: 10px;\n",
       "            height: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend .success { background-color: #2BD62E }\n",
       "        .graph-legend .failed { background-color: #DE322F }\n",
       "        .graph-legend .cancelled { background-color: #DDDDDD }\n",
       "        .graph-legend .in-progress { background-color: #53C9ED }\n",
       "        .graph-legend .caught-error { background-color: #FFA500 }\n",
       "    </style>\n",
       "    <div class=\"graph-legend\">\n",
       "        <ul>\n",
       "            <li>\n",
       "                <div class=\"success\"></div>\n",
       "                <span>Success</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"failed\"></div>\n",
       "                <span>Failed</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"cancelled\"></div>\n",
       "                <span>Cancelled</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"in-progress\"></div>\n",
       "                <span>In Progress</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"caught-error\"></div>\n",
       "                <span>Caught Error</span>\n",
       "            </li>\n",
       "        </ul>\n",
       "    </div>\n",
       "\n",
       "    <svg></svg>\n",
       "    <a href=\"https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:329542461890:execution:training-pipeline-2021-11-11-16-58-07:training-pipeline-2021-11-11-17-00-59\" target=\"_blank\"> Inspect in AWS Step Functions </a>\n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var element = document.getElementById('graph-131')\n",
       "\n",
       "    var options = {\n",
       "        width: parseFloat(getComputedStyle(element, null).width.replace(\"px\", \"\")),\n",
       "        height: 1000,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Training\", \"States\": {\"Training\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\", \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\", \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\", \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\", \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\", \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\", \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\", \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\", \"Tags.$\": \"$$.Execution.Input['Training'].Tags\", \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"}, \"Type\": \"Task\", \"Next\": \"Create Model\"}, \"Create Model\": {\"Parameters\": {\"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\", \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\", \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Configure Endpoint\"}, \"Configure Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\", \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"}, \"Type\": \"Task\", \"Next\": \"Deploy\"}, \"Deploy\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\", \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-131';\n",
       "    var events = { 'events': [{\"timestamp\": 1636650059.59, \"type\": \"ExecutionStarted\", \"id\": 1, \"previousEventId\": 0, \"executionStartedEventDetails\": {\"input\": \"{\\n    \\\"Training\\\": {\\n        \\\"AlgorithmSpecification\\\": {\\n            \\\"TrainingImage\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\\\",\\n            \\\"TrainingInputMode\\\": \\\"File\\\"\\n        },\\n        \\\"OutputDataConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\\\",\\n            \\\"KmsKeyId\\\": \\\"\\\"\\n        },\\n        \\\"StoppingCondition\\\": {\\n            \\\"MaxRuntimeInSeconds\\\": 86400\\n        },\\n        \\\"ResourceConfig\\\": {\\n            \\\"InstanceCount\\\": 1,\\n            \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n            \\\"VolumeSizeInGB\\\": 30\\n        },\\n        \\\"RoleArn\\\": \\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\",\\n        \\\"InputDataConfig\\\": [\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"train\\\"\\n            },\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"test\\\"\\n            }\\n        ],\\n        \\\"HyperParameters\\\": {\\n            \\\"_tuning_objective_metric\\\": \\\"\\\\\\\"val_loss\\\\\\\"\\\",\\n            \\\"batch_size\\\": \\\"229\\\",\\n            \\\"epochs\\\": \\\"41\\\",\\n            \\\"learning_rate\\\": \\\"0.14874578782070141\\\",\\n            \\\"sagemaker_container_log_level\\\": \\\"20\\\",\\n            \\\"sagemaker_estimator_class_name\\\": \\\"\\\\\\\"TensorFlow\\\\\\\"\\\",\\n            \\\"sagemaker_estimator_module\\\": \\\"\\\\\\\"sagemaker.tensorflow.estimator\\\\\\\"\\\",\\n            \\\"sagemaker_job_name\\\": \\\"\\\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\\\"\\\",\\n            \\\"sagemaker_program\\\": \\\"\\\\\\\"train.py\\\\\\\"\\\",\\n            \\\"sagemaker_region\\\": \\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\n            \\\"sagemaker_submit_directory\\\": \\\"\\\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\\\"\\\",\\n            \\\"model_dir\\\": \\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\"\\n        },\\n        \\\"TrainingJobName\\\": \\\"estimator-training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"Tags\\\": [],\\n        \\\"DebugHookConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-329542461890/\\\"\\n        }\\n    },\\n    \\\"Create Model\\\": {\\n        \\\"ModelName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"PrimaryContainer\\\": {\\n            \\\"Image\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.2-cpu\\\",\\n            \\\"Environment\\\": {\\n                \\\"SAGEMAKER_PROGRAM\\\": \\\"\\\",\\n                \\\"SAGEMAKER_SUBMIT_DIRECTORY\\\": \\\"\\\",\\n                \\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\": \\\"20\\\",\\n                \\\"SAGEMAKER_REGION\\\": \\\"us-east-1\\\"\\n            },\\n            \\\"ModelDataUrl\\\": \\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\\\"\\n        },\\n        \\\"ExecutionRoleArn\\\": \\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\"\\n    },\\n    \\\"Configure Endpoint\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"ProductionVariants\\\": [\\n            {\\n                \\\"InitialInstanceCount\\\": 1,\\n                \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n                \\\"ModelName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n                \\\"VariantName\\\": \\\"AllTraffic\\\"\\n            }\\n        ]\\n    },\\n    \\\"Deploy\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"EndpointName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\"\\n    }\\n}\", \"inputDetails\": {\"truncated\": false}, \"roleArn\": \"arn:aws:iam::329542461890:role/StepFunctionsWorkflowExecutionRole\"}}, {\"timestamp\": 1636650059.702, \"type\": \"TaskStateEntered\", \"id\": 2, \"previousEventId\": 0, \"stateEnteredEventDetails\": {\"name\": \"Training\", \"input\": \"{\\n    \\\"Training\\\": {\\n        \\\"AlgorithmSpecification\\\": {\\n            \\\"TrainingImage\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\\\",\\n            \\\"TrainingInputMode\\\": \\\"File\\\"\\n        },\\n        \\\"OutputDataConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\\\",\\n            \\\"KmsKeyId\\\": \\\"\\\"\\n        },\\n        \\\"StoppingCondition\\\": {\\n            \\\"MaxRuntimeInSeconds\\\": 86400\\n        },\\n        \\\"ResourceConfig\\\": {\\n            \\\"InstanceCount\\\": 1,\\n            \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n            \\\"VolumeSizeInGB\\\": 30\\n        },\\n        \\\"RoleArn\\\": \\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\",\\n        \\\"InputDataConfig\\\": [\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"train\\\"\\n            },\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ChannelName\\\": \\\"test\\\"\\n            }\\n        ],\\n        \\\"HyperParameters\\\": {\\n            \\\"_tuning_objective_metric\\\": \\\"\\\\\\\"val_loss\\\\\\\"\\\",\\n            \\\"batch_size\\\": \\\"229\\\",\\n            \\\"epochs\\\": \\\"41\\\",\\n            \\\"learning_rate\\\": \\\"0.14874578782070141\\\",\\n            \\\"sagemaker_container_log_level\\\": \\\"20\\\",\\n            \\\"sagemaker_estimator_class_name\\\": \\\"\\\\\\\"TensorFlow\\\\\\\"\\\",\\n            \\\"sagemaker_estimator_module\\\": \\\"\\\\\\\"sagemaker.tensorflow.estimator\\\\\\\"\\\",\\n            \\\"sagemaker_job_name\\\": \\\"\\\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\\\"\\\",\\n            \\\"sagemaker_program\\\": \\\"\\\\\\\"train.py\\\\\\\"\\\",\\n            \\\"sagemaker_region\\\": \\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\n            \\\"sagemaker_submit_directory\\\": \\\"\\\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\\\"\\\",\\n            \\\"model_dir\\\": \\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\"\\n        },\\n        \\\"TrainingJobName\\\": \\\"estimator-training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"Tags\\\": [],\\n        \\\"DebugHookConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-329542461890/\\\"\\n        }\\n    },\\n    \\\"Create Model\\\": {\\n        \\\"ModelName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"PrimaryContainer\\\": {\\n            \\\"Image\\\": \\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.2-cpu\\\",\\n            \\\"Environment\\\": {\\n                \\\"SAGEMAKER_PROGRAM\\\": \\\"\\\",\\n                \\\"SAGEMAKER_SUBMIT_DIRECTORY\\\": \\\"\\\",\\n                \\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\": \\\"20\\\",\\n                \\\"SAGEMAKER_REGION\\\": \\\"us-east-1\\\"\\n            },\\n            \\\"ModelDataUrl\\\": \\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\\\"\\n        },\\n        \\\"ExecutionRoleArn\\\": \\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\"\\n    },\\n    \\\"Configure Endpoint\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"ProductionVariants\\\": [\\n            {\\n                \\\"InitialInstanceCount\\\": 1,\\n                \\\"InstanceType\\\": \\\"ml.c5.xlarge\\\",\\n                \\\"ModelName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n                \\\"VariantName\\\": \\\"AllTraffic\\\"\\n            }\\n        ]\\n    },\\n    \\\"Deploy\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\",\\n        \\\"EndpointName\\\": \\\"training-pipeline-2021-11-11-17-00-59\\\"\\n    }\\n}\", \"inputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650059.702, \"type\": \"TaskScheduled\", \"id\": 3, \"previousEventId\": 2, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"HyperParameters\\\":{\\\"_tuning_objective_metric\\\":\\\"\\\\\\\"val_loss\\\\\\\"\\\",\\\"batch_size\\\":\\\"229\\\",\\\"epochs\\\":\\\"41\\\",\\\"learning_rate\\\":\\\"0.14874578782070141\\\",\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"sagemaker_estimator_class_name\\\":\\\"\\\\\\\"TensorFlow\\\\\\\"\\\",\\\"sagemaker_estimator_module\\\":\\\"\\\\\\\"sagemaker.tensorflow.estimator\\\\\\\"\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\\\"\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\"},\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/\\\"},\\\"AlgorithmSpecification\\\":{\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\\\",\\\"TrainingInputMode\\\":\\\"File\\\"},\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400},\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2021-11-11-17-00-59\\\",\\\"OutputDataConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\\\",\\\"KmsKeyId\\\":\\\"\\\"},\\\"ResourceConfig\\\":{\\\"InstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"VolumeSizeInGB\\\":30},\\\"InputDataConfig\\\":[{\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\"}},\\\"ChannelName\\\":\\\"train\\\"},{\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\"}},\\\"ChannelName\\\":\\\"test\\\"}],\\\"RoleArn\\\":\\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\",\\\"Tags\\\":[{\\\"Key\\\":\\\"MANAGED_BY_AWS\\\",\\\"Value\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\"}]}\"}}, {\"timestamp\": 1636650059.885, \"type\": \"TaskStarted\", \"id\": 4, \"previousEventId\": 3, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\"}}, {\"timestamp\": 1636650060.271, \"type\": \"TaskSubmitted\", \"id\": 5, \"previousEventId\": 4, \"taskSubmittedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"output\": \"{\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"f39724db-a443-42bb-935b-4b131427cc9c\\\"],\\\"Content-Length\\\":[\\\"122\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:00:59 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"122\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:00:59 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"f39724db-a443-42bb-935b-4b131427cc9c\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"f39724db-a443-42bb-935b-4b131427cc9c\\\"},\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:training-job/estimator-training-pipeline-2021-11-11-17-00-59\\\"}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.224, \"type\": \"TaskSucceeded\", \"id\": 6, \"previousEventId\": 5, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"output\": \"{\\\"AlgorithmSpecification\\\":{\\\"EnableSageMakerMetricsTimeSeries\\\":false,\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\\\",\\\"TrainingInputMode\\\":\\\"File\\\"},\\\"BillableTimeInSeconds\\\":73,\\\"CreationTime\\\":1636650060138,\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/\\\"},\\\"EnableInterContainerTrafficEncryption\\\":false,\\\"EnableManagedSpotTraining\\\":false,\\\"EnableNetworkIsolation\\\":false,\\\"HyperParameters\\\":{\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"batch_size\\\":\\\"229\\\",\\\"sagemaker_estimator_class_name\\\":\\\"\\\\\\\"TensorFlow\\\\\\\"\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"_tuning_objective_metric\\\":\\\"\\\\\\\"val_loss\\\\\\\"\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\\\"\\\",\\\"epochs\\\":\\\"41\\\",\\\"learning_rate\\\":\\\"0.14874578782070141\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\\\"\\\",\\\"sagemaker_estimator_module\\\":\\\"\\\\\\\"sagemaker.tensorflow.estimator\\\\\\\"\\\"},\\\"InputDataConfig\\\":[{\\\"ChannelName\\\":\\\"train\\\",\\\"CompressionType\\\":\\\"None\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\\\"}},\\\"RecordWrapperType\\\":\\\"None\\\"},{\\\"ChannelName\\\":\\\"test\\\",\\\"CompressionType\\\":\\\"None\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\\\"}},\\\"RecordWrapperType\\\":\\\"None\\\"}],\\\"LastModifiedTime\\\":1636650307283,\\\"ModelArtifacts\\\":{\\\"S3ModelArtifacts\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\\\"},\\\"OutputDataConfig\\\":{\\\"KmsKeyId\\\":\\\"\\\",\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\\\"},\\\"ProfilingStatus\\\":\\\"Disabled\\\",\\\"ResourceConfig\\\":{\\\"InstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"VolumeSizeInGB\\\":30},\\\"RoleArn\\\":\\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"],\\\"Content-Length\\\":[\\\"3506\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:13 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"3506\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:13 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"},\\\"SecondaryStatus\\\":\\\"Completed\\\",\\\"SecondaryStatusTransitions\\\":[{\\\"EndTime\\\":1636650234448,\\\"StartTime\\\":1636650060138,\\\"Status\\\":\\\"Starting\\\",\\\"StatusMessage\\\":\\\"Preparing the instances for training\\\"},{\\\"EndTime\\\":1636650268652,\\\"StartTime\\\":1636650234448,\\\"Status\\\":\\\"Downloading\\\",\\\"StatusMessage\\\":\\\"Downloading input data\\\"},{\\\"EndTime\\\":1636650300094,\\\"StartTime\\\":1636650268652,\\\"Status\\\":\\\"Training\\\",\\\"StatusMessage\\\":\\\"Training image download completed. Training in progress.\\\"},{\\\"EndTime\\\":1636650307283,\\\"StartTime\\\":1636650300094,\\\"Status\\\":\\\"Uploading\\\",\\\"StatusMessage\\\":\\\"Uploading generated training model\\\"},{\\\"EndTime\\\":1636650307283,\\\"StartTime\\\":1636650307283,\\\"Status\\\":\\\"Completed\\\",\\\"StatusMessage\\\":\\\"Training job completed\\\"}],\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400},\\\"TrainingEndTime\\\":1636650307283,\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:training-job/estimator-training-pipeline-2021-11-11-17-00-59\\\",\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2021-11-11-17-00-59\\\",\\\"TrainingJobStatus\\\":\\\"Completed\\\",\\\"TrainingStartTime\\\":1636650234448,\\\"TrainingTimeInSeconds\\\":73,\\\"Tags\\\":{\\\"MANAGED_BY_AWS\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\",\\\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\\\":\\\"arn:aws:states:us-east-1:329542461890:execution:training-pipeline-2021-11-11-16-58-07:training-pipeline-2021-11-11-17-00-59\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.224, \"type\": \"TaskStateExited\", \"id\": 7, \"previousEventId\": 6, \"stateExitedEventDetails\": {\"name\": \"Training\", \"output\": \"{\\\"AlgorithmSpecification\\\":{\\\"EnableSageMakerMetricsTimeSeries\\\":false,\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\\\",\\\"TrainingInputMode\\\":\\\"File\\\"},\\\"BillableTimeInSeconds\\\":73,\\\"CreationTime\\\":1636650060138,\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/\\\"},\\\"EnableInterContainerTrafficEncryption\\\":false,\\\"EnableManagedSpotTraining\\\":false,\\\"EnableNetworkIsolation\\\":false,\\\"HyperParameters\\\":{\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"batch_size\\\":\\\"229\\\",\\\"sagemaker_estimator_class_name\\\":\\\"\\\\\\\"TensorFlow\\\\\\\"\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"_tuning_objective_metric\\\":\\\"\\\\\\\"val_loss\\\\\\\"\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\\\"\\\",\\\"epochs\\\":\\\"41\\\",\\\"learning_rate\\\":\\\"0.14874578782070141\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\\\"\\\",\\\"sagemaker_estimator_module\\\":\\\"\\\\\\\"sagemaker.tensorflow.estimator\\\\\\\"\\\"},\\\"InputDataConfig\\\":[{\\\"ChannelName\\\":\\\"train\\\",\\\"CompressionType\\\":\\\"None\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\\\"}},\\\"RecordWrapperType\\\":\\\"None\\\"},{\\\"ChannelName\\\":\\\"test\\\",\\\"CompressionType\\\":\\\"None\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\\\"}},\\\"RecordWrapperType\\\":\\\"None\\\"}],\\\"LastModifiedTime\\\":1636650307283,\\\"ModelArtifacts\\\":{\\\"S3ModelArtifacts\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\\\"},\\\"OutputDataConfig\\\":{\\\"KmsKeyId\\\":\\\"\\\",\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\\\"},\\\"ProfilingStatus\\\":\\\"Disabled\\\",\\\"ResourceConfig\\\":{\\\"InstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"VolumeSizeInGB\\\":30},\\\"RoleArn\\\":\\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"],\\\"Content-Length\\\":[\\\"3506\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:13 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"3506\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:13 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"},\\\"SecondaryStatus\\\":\\\"Completed\\\",\\\"SecondaryStatusTransitions\\\":[{\\\"EndTime\\\":1636650234448,\\\"StartTime\\\":1636650060138,\\\"Status\\\":\\\"Starting\\\",\\\"StatusMessage\\\":\\\"Preparing the instances for training\\\"},{\\\"EndTime\\\":1636650268652,\\\"StartTime\\\":1636650234448,\\\"Status\\\":\\\"Downloading\\\",\\\"StatusMessage\\\":\\\"Downloading input data\\\"},{\\\"EndTime\\\":1636650300094,\\\"StartTime\\\":1636650268652,\\\"Status\\\":\\\"Training\\\",\\\"StatusMessage\\\":\\\"Training image download completed. Training in progress.\\\"},{\\\"EndTime\\\":1636650307283,\\\"StartTime\\\":1636650300094,\\\"Status\\\":\\\"Uploading\\\",\\\"StatusMessage\\\":\\\"Uploading generated training model\\\"},{\\\"EndTime\\\":1636650307283,\\\"StartTime\\\":1636650307283,\\\"Status\\\":\\\"Completed\\\",\\\"StatusMessage\\\":\\\"Training job completed\\\"}],\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400},\\\"TrainingEndTime\\\":1636650307283,\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:training-job/estimator-training-pipeline-2021-11-11-17-00-59\\\",\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2021-11-11-17-00-59\\\",\\\"TrainingJobStatus\\\":\\\"Completed\\\",\\\"TrainingStartTime\\\":1636650234448,\\\"TrainingTimeInSeconds\\\":73,\\\"Tags\\\":{\\\"MANAGED_BY_AWS\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\",\\\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\\\":\\\"arn:aws:states:us-east-1:329542461890:execution:training-pipeline-2021-11-11-16-58-07:training-pipeline-2021-11-11-17-00-59\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.239, \"type\": \"TaskStateEntered\", \"id\": 8, \"previousEventId\": 7, \"stateEnteredEventDetails\": {\"name\": \"Create Model\", \"input\": \"{\\\"AlgorithmSpecification\\\":{\\\"EnableSageMakerMetricsTimeSeries\\\":false,\\\"TrainingImage\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\\\",\\\"TrainingInputMode\\\":\\\"File\\\"},\\\"BillableTimeInSeconds\\\":73,\\\"CreationTime\\\":1636650060138,\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/\\\"},\\\"EnableInterContainerTrafficEncryption\\\":false,\\\"EnableManagedSpotTraining\\\":false,\\\"EnableNetworkIsolation\\\":false,\\\"HyperParameters\\\":{\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"batch_size\\\":\\\"229\\\",\\\"sagemaker_estimator_class_name\\\":\\\"\\\\\\\"TensorFlow\\\\\\\"\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"train.py\\\\\\\"\\\",\\\"_tuning_objective_metric\\\":\\\"\\\\\\\"val_loss\\\\\\\"\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\",\\\"model_dir\\\":\\\"\\\\\\\"/opt/ml/model\\\\\\\"\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\\\"\\\",\\\"epochs\\\":\\\"41\\\",\\\"learning_rate\\\":\\\"0.14874578782070141\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\\\"\\\",\\\"sagemaker_estimator_module\\\":\\\"\\\\\\\"sagemaker.tensorflow.estimator\\\\\\\"\\\"},\\\"InputDataConfig\\\":[{\\\"ChannelName\\\":\\\"train\\\",\\\"CompressionType\\\":\\\"None\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\\\"}},\\\"RecordWrapperType\\\":\\\"None\\\"},{\\\"ChannelName\\\":\\\"test\\\",\\\"CompressionType\\\":\\\"None\\\",\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\",\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\\\"}},\\\"RecordWrapperType\\\":\\\"None\\\"}],\\\"LastModifiedTime\\\":1636650307283,\\\"ModelArtifacts\\\":{\\\"S3ModelArtifacts\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\\\"},\\\"OutputDataConfig\\\":{\\\"KmsKeyId\\\":\\\"\\\",\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\\\"},\\\"ProfilingStatus\\\":\\\"Disabled\\\",\\\"ResourceConfig\\\":{\\\"InstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"VolumeSizeInGB\\\":30},\\\"RoleArn\\\":\\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"],\\\"Content-Length\\\":[\\\"3506\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:13 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"3506\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:13 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"d3b349bc-0c46-456a-b4a2-adcc0dbfd0dd\\\"},\\\"SecondaryStatus\\\":\\\"Completed\\\",\\\"SecondaryStatusTransitions\\\":[{\\\"EndTime\\\":1636650234448,\\\"StartTime\\\":1636650060138,\\\"Status\\\":\\\"Starting\\\",\\\"StatusMessage\\\":\\\"Preparing the instances for training\\\"},{\\\"EndTime\\\":1636650268652,\\\"StartTime\\\":1636650234448,\\\"Status\\\":\\\"Downloading\\\",\\\"StatusMessage\\\":\\\"Downloading input data\\\"},{\\\"EndTime\\\":1636650300094,\\\"StartTime\\\":1636650268652,\\\"Status\\\":\\\"Training\\\",\\\"StatusMessage\\\":\\\"Training image download completed. Training in progress.\\\"},{\\\"EndTime\\\":1636650307283,\\\"StartTime\\\":1636650300094,\\\"Status\\\":\\\"Uploading\\\",\\\"StatusMessage\\\":\\\"Uploading generated training model\\\"},{\\\"EndTime\\\":1636650307283,\\\"StartTime\\\":1636650307283,\\\"Status\\\":\\\"Completed\\\",\\\"StatusMessage\\\":\\\"Training job completed\\\"}],\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400},\\\"TrainingEndTime\\\":1636650307283,\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:training-job/estimator-training-pipeline-2021-11-11-17-00-59\\\",\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2021-11-11-17-00-59\\\",\\\"TrainingJobStatus\\\":\\\"Completed\\\",\\\"TrainingStartTime\\\":1636650234448,\\\"TrainingTimeInSeconds\\\":73,\\\"Tags\\\":{\\\"MANAGED_BY_AWS\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\",\\\"AWS_STEP_FUNCTIONS_EXECUTION_ARN\\\":\\\"arn:aws:states:us-east-1:329542461890:execution:training-pipeline-2021-11-11-16-58-07:training-pipeline-2021-11-11-17-00-59\\\"}}\", \"inputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.239, \"type\": \"TaskScheduled\", \"id\": 9, \"previousEventId\": 8, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createModel\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"ExecutionRoleArn\\\":\\\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\\\",\\\"PrimaryContainer\\\":{\\\"Image\\\":\\\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.2-cpu\\\",\\\"Environment\\\":{\\\"SAGEMAKER_PROGRAM\\\":\\\"\\\",\\\"SAGEMAKER_SUBMIT_DIRECTORY\\\":\\\"\\\",\\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\":\\\"20\\\",\\\"SAGEMAKER_REGION\\\":\\\"us-east-1\\\"},\\\"ModelDataUrl\\\":\\\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\\\"},\\\"ModelName\\\":\\\"training-pipeline-2021-11-11-17-00-59\\\"}\"}}, {\"timestamp\": 1636650314.257, \"type\": \"TaskStarted\", \"id\": 10, \"previousEventId\": 9, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createModel\"}}, {\"timestamp\": 1636650314.58, \"type\": \"TaskSucceeded\", \"id\": 11, \"previousEventId\": 10, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createModel\", \"output\": \"{\\\"ModelArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:model/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"],\\\"Content-Length\\\":[\\\"99\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"99\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.58, \"type\": \"TaskStateExited\", \"id\": 12, \"previousEventId\": 11, \"stateExitedEventDetails\": {\"name\": \"Create Model\", \"output\": \"{\\\"ModelArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:model/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"],\\\"Content-Length\\\":[\\\"99\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"99\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.589, \"type\": \"TaskStateEntered\", \"id\": 13, \"previousEventId\": 12, \"stateEnteredEventDetails\": {\"name\": \"Configure Endpoint\", \"input\": \"{\\\"ModelArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:model/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"],\\\"Content-Length\\\":[\\\"99\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"99\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"c2b10ffd-9c74-42a6-8477-b0e561683d21\\\"}}\", \"inputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.589, \"type\": \"TaskScheduled\", \"id\": 14, \"previousEventId\": 13, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpointConfig\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"ProductionVariants\\\":[{\\\"InitialInstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.xlarge\\\",\\\"ModelName\\\":\\\"training-pipeline-2021-11-11-17-00-59\\\",\\\"VariantName\\\":\\\"AllTraffic\\\"}],\\\"EndpointConfigName\\\":\\\"training-pipeline-2021-11-11-17-00-59\\\"}\"}}, {\"timestamp\": 1636650314.604, \"type\": \"TaskStarted\", \"id\": 15, \"previousEventId\": 14, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpointConfig\"}}, {\"timestamp\": 1636650314.706, \"type\": \"TaskSucceeded\", \"id\": 16, \"previousEventId\": 15, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpointConfig\", \"output\": \"{\\\"EndpointConfigArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:endpoint-config/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"],\\\"Content-Length\\\":[\\\"118\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"118\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.706, \"type\": \"TaskStateExited\", \"id\": 17, \"previousEventId\": 16, \"stateExitedEventDetails\": {\"name\": \"Configure Endpoint\", \"output\": \"{\\\"EndpointConfigArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:endpoint-config/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"],\\\"Content-Length\\\":[\\\"118\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"118\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.712, \"type\": \"TaskStateEntered\", \"id\": 18, \"previousEventId\": 17, \"stateEnteredEventDetails\": {\"name\": \"Deploy\", \"input\": \"{\\\"EndpointConfigArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:endpoint-config/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"],\\\"Content-Length\\\":[\\\"118\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"118\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"d454eef6-3c31-4d6f-aebd-46d484ce88d0\\\"}}\", \"inputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650314.712, \"type\": \"TaskScheduled\", \"id\": 19, \"previousEventId\": 18, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpoint\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"EndpointName\\\":\\\"training-pipeline-2021-11-11-17-00-59\\\",\\\"EndpointConfigName\\\":\\\"training-pipeline-2021-11-11-17-00-59\\\"}\"}}, {\"timestamp\": 1636650314.727, \"type\": \"TaskStarted\", \"id\": 20, \"previousEventId\": 19, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpoint\"}}, {\"timestamp\": 1636650315.088, \"type\": \"TaskSucceeded\", \"id\": 21, \"previousEventId\": 20, \"taskSucceededEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createEndpoint\", \"output\": \"{\\\"EndpointArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:endpoint/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"],\\\"Content-Length\\\":[\\\"105\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"105\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650315.088, \"type\": \"TaskStateExited\", \"id\": 22, \"previousEventId\": 21, \"stateExitedEventDetails\": {\"name\": \"Deploy\", \"output\": \"{\\\"EndpointArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:endpoint/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"],\\\"Content-Length\\\":[\\\"105\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"105\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"}}\", \"outputDetails\": {\"truncated\": false}}}, {\"timestamp\": 1636650315.088, \"type\": \"ExecutionSucceeded\", \"id\": 23, \"previousEventId\": 22, \"executionSucceededEventDetails\": {\"output\": \"{\\\"EndpointArn\\\":\\\"arn:aws:sagemaker:us-east-1:329542461890:endpoint/training-pipeline-2021-11-11-17-00-59\\\",\\\"SdkHttpMetadata\\\":{\\\"AllHttpHeaders\\\":{\\\"Keep-Alive\\\":[\\\"timeout=70\\\"],\\\"Connection\\\":[\\\"keep-alive\\\"],\\\"x-amzn-RequestId\\\":[\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"],\\\"Content-Length\\\":[\\\"105\\\"],\\\"Date\\\":[\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\"],\\\"Content-Type\\\":[\\\"application/x-amz-json-1.1\\\"]},\\\"HttpHeaders\\\":{\\\"Connection\\\":\\\"keep-alive\\\",\\\"Content-Length\\\":\\\"105\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Thu, 11 Nov 2021 17:05:14 GMT\\\",\\\"Keep-Alive\\\":\\\"timeout=70\\\",\\\"x-amzn-RequestId\\\":\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"b6e59da0-cda4-43c4-ad87-d2566663142c\\\"}}\", \"outputDetails\": {\"truncated\": false}}}] };\n",
       "\n",
       "    var graph = new sfn.StateMachineExecutionGraph(definition, events, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEFORE proceeding with the rest of the notebook:\n",
    "\n",
    "Wait until the workflow completes with status **Succeeded**, which will take a few minutes.  You can check status with `render_progress` above, or open in a new browser tab the **Inspect in AWS Step Functions** link in the cell output.  \n",
    "\n",
    "To view the details of the completed workflow execution, from model training through deployment, use the `list_events` method, which lists all events in the workflow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': datetime.datetime(2021, 11, 11, 17, 1, 0, 271000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskSubmitted',\n",
       "  'id': 5,\n",
       "  'previousEventId': 4,\n",
       "  'taskSubmittedEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createTrainingJob.sync',\n",
       "   'output': '{\"SdkHttpMetadata\":{\"AllHttpHeaders\":{\"Keep-Alive\":[\"timeout=70\"],\"Connection\":[\"keep-alive\"],\"x-amzn-RequestId\":[\"f39724db-a443-42bb-935b-4b131427cc9c\"],\"Content-Length\":[\"122\"],\"Date\":[\"Thu, 11 Nov 2021 17:00:59 GMT\"],\"Content-Type\":[\"application/x-amz-json-1.1\"]},\"HttpHeaders\":{\"Connection\":\"keep-alive\",\"Content-Length\":\"122\",\"Content-Type\":\"application/x-amz-json-1.1\",\"Date\":\"Thu, 11 Nov 2021 17:00:59 GMT\",\"Keep-Alive\":\"timeout=70\",\"x-amzn-RequestId\":\"f39724db-a443-42bb-935b-4b131427cc9c\"},\"HttpStatusCode\":200},\"SdkResponseMetadata\":{\"RequestId\":\"f39724db-a443-42bb-935b-4b131427cc9c\"},\"TrainingJobArn\":\"arn:aws:sagemaker:us-east-1:329542461890:training-job/estimator-training-pipeline-2021-11-11-17-00-59\"}',\n",
       "   'outputDetails': {'truncated': False}}},\n",
       " {'timestamp': datetime.datetime(2021, 11, 11, 17, 0, 59, 885000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStarted',\n",
       "  'id': 4,\n",
       "  'previousEventId': 3,\n",
       "  'taskStartedEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createTrainingJob.sync'}},\n",
       " {'timestamp': datetime.datetime(2021, 11, 11, 17, 0, 59, 702000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskScheduled',\n",
       "  'id': 3,\n",
       "  'previousEventId': 2,\n",
       "  'taskScheduledEventDetails': {'resourceType': 'sagemaker',\n",
       "   'resource': 'createTrainingJob.sync',\n",
       "   'region': 'us-east-1',\n",
       "   'parameters': '{\"HyperParameters\":{\"_tuning_objective_metric\":\"\\\\\"val_loss\\\\\"\",\"batch_size\":\"229\",\"epochs\":\"41\",\"learning_rate\":\"0.14874578782070141\",\"sagemaker_container_log_level\":\"20\",\"sagemaker_estimator_class_name\":\"\\\\\"TensorFlow\\\\\"\",\"sagemaker_estimator_module\":\"\\\\\"sagemaker.tensorflow.estimator\\\\\"\",\"sagemaker_job_name\":\"\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\"\",\"sagemaker_program\":\"\\\\\"train.py\\\\\"\",\"sagemaker_region\":\"\\\\\"us-east-1\\\\\"\",\"sagemaker_submit_directory\":\"\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\"\",\"model_dir\":\"\\\\\"/opt/ml/model\\\\\"\"},\"DebugHookConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-329542461890/\"},\"AlgorithmSpecification\":{\"TrainingImage\":\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\",\"TrainingInputMode\":\"File\"},\"StoppingCondition\":{\"MaxRuntimeInSeconds\":86400},\"TrainingJobName\":\"estimator-training-pipeline-2021-11-11-17-00-59\",\"OutputDataConfig\":{\"S3OutputPath\":\"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\",\"KmsKeyId\":\"\"},\"ResourceConfig\":{\"InstanceCount\":1,\"InstanceType\":\"ml.c5.xlarge\",\"VolumeSizeInGB\":30},\"InputDataConfig\":[{\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3Prefix\",\"S3Uri\":\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\",\"S3DataDistributionType\":\"FullyReplicated\"}},\"ChannelName\":\"train\"},{\"DataSource\":{\"S3DataSource\":{\"S3DataType\":\"S3Prefix\",\"S3Uri\":\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\",\"S3DataDistributionType\":\"FullyReplicated\"}},\"ChannelName\":\"test\"}],\"RoleArn\":\"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\",\"Tags\":[{\"Key\":\"MANAGED_BY_AWS\",\"Value\":\"STARTED_BY_STEP_FUNCTIONS\"}]}'}},\n",
       " {'timestamp': datetime.datetime(2021, 11, 11, 17, 0, 59, 702000, tzinfo=tzlocal()),\n",
       "  'type': 'TaskStateEntered',\n",
       "  'id': 2,\n",
       "  'previousEventId': 0,\n",
       "  'stateEnteredEventDetails': {'name': 'Training',\n",
       "   'input': '{\\n    \"Training\": {\\n        \"AlgorithmSpecification\": {\\n            \"TrainingImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\",\\n            \"TrainingInputMode\": \"File\"\\n        },\\n        \"OutputDataConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\",\\n            \"KmsKeyId\": \"\"\\n        },\\n        \"StoppingCondition\": {\\n            \"MaxRuntimeInSeconds\": 86400\\n        },\\n        \"ResourceConfig\": {\\n            \"InstanceCount\": 1,\\n            \"InstanceType\": \"ml.c5.xlarge\",\\n            \"VolumeSizeInGB\": 30\\n        },\\n        \"RoleArn\": \"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\",\\n        \"InputDataConfig\": [\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"train\"\\n            },\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"test\"\\n            }\\n        ],\\n        \"HyperParameters\": {\\n            \"_tuning_objective_metric\": \"\\\\\"val_loss\\\\\"\",\\n            \"batch_size\": \"229\",\\n            \"epochs\": \"41\",\\n            \"learning_rate\": \"0.14874578782070141\",\\n            \"sagemaker_container_log_level\": \"20\",\\n            \"sagemaker_estimator_class_name\": \"\\\\\"TensorFlow\\\\\"\",\\n            \"sagemaker_estimator_module\": \"\\\\\"sagemaker.tensorflow.estimator\\\\\"\",\\n            \"sagemaker_job_name\": \"\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\"\",\\n            \"sagemaker_program\": \"\\\\\"train.py\\\\\"\",\\n            \"sagemaker_region\": \"\\\\\"us-east-1\\\\\"\",\\n            \"sagemaker_submit_directory\": \"\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\"\",\\n            \"model_dir\": \"\\\\\"/opt/ml/model\\\\\"\"\\n        },\\n        \"TrainingJobName\": \"estimator-training-pipeline-2021-11-11-17-00-59\",\\n        \"Tags\": [],\\n        \"DebugHookConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-329542461890/\"\\n        }\\n    },\\n    \"Create Model\": {\\n        \"ModelName\": \"training-pipeline-2021-11-11-17-00-59\",\\n        \"PrimaryContainer\": {\\n            \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.2-cpu\",\\n            \"Environment\": {\\n                \"SAGEMAKER_PROGRAM\": \"\",\\n                \"SAGEMAKER_SUBMIT_DIRECTORY\": \"\",\\n                \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\\n                \"SAGEMAKER_REGION\": \"us-east-1\"\\n            },\\n            \"ModelDataUrl\": \"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\"\\n        },\\n        \"ExecutionRoleArn\": \"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\"\\n    },\\n    \"Configure Endpoint\": {\\n        \"EndpointConfigName\": \"training-pipeline-2021-11-11-17-00-59\",\\n        \"ProductionVariants\": [\\n            {\\n                \"InitialInstanceCount\": 1,\\n                \"InstanceType\": \"ml.c5.xlarge\",\\n                \"ModelName\": \"training-pipeline-2021-11-11-17-00-59\",\\n                \"VariantName\": \"AllTraffic\"\\n            }\\n        ]\\n    },\\n    \"Deploy\": {\\n        \"EndpointConfigName\": \"training-pipeline-2021-11-11-17-00-59\",\\n        \"EndpointName\": \"training-pipeline-2021-11-11-17-00-59\"\\n    }\\n}',\n",
       "   'inputDetails': {'truncated': False}}},\n",
       " {'timestamp': datetime.datetime(2021, 11, 11, 17, 0, 59, 590000, tzinfo=tzlocal()),\n",
       "  'type': 'ExecutionStarted',\n",
       "  'id': 1,\n",
       "  'previousEventId': 0,\n",
       "  'executionStartedEventDetails': {'input': '{\\n    \"Training\": {\\n        \"AlgorithmSpecification\": {\\n            \"TrainingImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.2-cpu-py37\",\\n            \"TrainingInputMode\": \"File\"\\n        },\\n        \"OutputDataConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models\",\\n            \"KmsKeyId\": \"\"\\n        },\\n        \"StoppingCondition\": {\\n            \"MaxRuntimeInSeconds\": 86400\\n        },\\n        \"ResourceConfig\": {\\n            \"InstanceCount\": 1,\\n            \"InstanceType\": \"ml.c5.xlarge\",\\n            \"VolumeSizeInGB\": 30\\n        },\\n        \"RoleArn\": \"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\",\\n        \"InputDataConfig\": [\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/train\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"train\"\\n            },\\n            {\\n                \"DataSource\": {\\n                    \"S3DataSource\": {\\n                        \"S3DataType\": \"S3Prefix\",\\n                        \"S3Uri\": \"s3://sagemaker-us-east-1-329542461890/tf-2-workflow/data/test\",\\n                        \"S3DataDistributionType\": \"FullyReplicated\"\\n                    }\\n                },\\n                \"ChannelName\": \"test\"\\n            }\\n        ],\\n        \"HyperParameters\": {\\n            \"_tuning_objective_metric\": \"\\\\\"val_loss\\\\\"\",\\n            \"batch_size\": \"229\",\\n            \"epochs\": \"41\",\\n            \"learning_rate\": \"0.14874578782070141\",\\n            \"sagemaker_container_log_level\": \"20\",\\n            \"sagemaker_estimator_class_name\": \"\\\\\"TensorFlow\\\\\"\",\\n            \"sagemaker_estimator_module\": \"\\\\\"sagemaker.tensorflow.estimator\\\\\"\",\\n            \"sagemaker_job_name\": \"\\\\\"training-pipeline-2021-11-11-16-58-07/estimator-source\\\\\"\",\\n            \"sagemaker_program\": \"\\\\\"train.py\\\\\"\",\\n            \"sagemaker_region\": \"\\\\\"us-east-1\\\\\"\",\\n            \"sagemaker_submit_directory\": \"\\\\\"s3://sagemaker-us-east-1-329542461890/tf-2-workflow-11-16-42-53/source/sourcedir.tar.gz\\\\\"\",\\n            \"model_dir\": \"\\\\\"/opt/ml/model\\\\\"\"\\n        },\\n        \"TrainingJobName\": \"estimator-training-pipeline-2021-11-11-17-00-59\",\\n        \"Tags\": [],\\n        \"DebugHookConfig\": {\\n            \"S3OutputPath\": \"s3://sagemaker-us-east-1-329542461890/\"\\n        }\\n    },\\n    \"Create Model\": {\\n        \"ModelName\": \"training-pipeline-2021-11-11-17-00-59\",\\n        \"PrimaryContainer\": {\\n            \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.2-cpu\",\\n            \"Environment\": {\\n                \"SAGEMAKER_PROGRAM\": \"\",\\n                \"SAGEMAKER_SUBMIT_DIRECTORY\": \"\",\\n                \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\\n                \"SAGEMAKER_REGION\": \"us-east-1\"\\n            },\\n            \"ModelDataUrl\": \"s3://sagemaker-us-east-1-329542461890/training-pipeline-2021-11-11-16-58-07/models/estimator-training-pipeline-2021-11-11-17-00-59/output/model.tar.gz\"\\n        },\\n        \"ExecutionRoleArn\": \"arn:aws:iam::329542461890:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\"\\n    },\\n    \"Configure Endpoint\": {\\n        \"EndpointConfigName\": \"training-pipeline-2021-11-11-17-00-59\",\\n        \"ProductionVariants\": [\\n            {\\n                \"InitialInstanceCount\": 1,\\n                \"InstanceType\": \"ml.c5.xlarge\",\\n                \"ModelName\": \"training-pipeline-2021-11-11-17-00-59\",\\n                \"VariantName\": \"AllTraffic\"\\n            }\\n        ]\\n    },\\n    \"Deploy\": {\\n        \"EndpointConfigName\": \"training-pipeline-2021-11-11-17-00-59\",\\n        \"EndpointName\": \"training-pipeline-2021-11-11-17-00-59\"\\n    }\\n}',\n",
       "   'inputDetails': {'truncated': False},\n",
       "   'roleArn': 'arn:aws:iam::329542461890:role/StepFunctionsWorkflowExecutionRole'}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_events(reverse_order=True, html=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list of events, we can extract the name of the endpoint that was set up by the workflow.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-11-17-00-59\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "endpoint_name_suffix = re.search('endpoint\\Wtraining\\Wpipeline\\W([a-zA-Z0-9\\W]+?)\"', str(execution.list_events())).group(1)\n",
    "print(endpoint_name_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the endpoint name, we can use it to instantiate a TensorFlowPredictor object that wraps the endpoint.  This TensorFlowPredictor can be used to make predictions, as shown in the following code cell.  \n",
    "\n",
    "#### BEFORE running the following code cell:\n",
    "\n",
    "Go to the [SageMaker console](https://console.aws.amazon.com/sagemaker/), click **Endpoints** in the left panel, and make sure that the endpoint status is **InService**.  If the status is **Creating**, wait until it changes, which may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \t[28.4 29.6 27.4 29.6 27.4 30.5 27.3 23.4 21.4 37.4]\n",
      "target values: \t[[ 7.2]\n",
      " [18.8]\n",
      " [19. ]\n",
      " [27. ]\n",
      " [22.2]\n",
      " [24.5]\n",
      " [31.2]\n",
      " [22.9]\n",
      " [20.5]\n",
      " [23.2]]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlowPredictor\n",
    "\n",
    "workflow_predictor = TensorFlowPredictor('training-pipeline-' + endpoint_name_suffix)\n",
    "\n",
    "results = workflow_predictor.predict(x_test[:10])['predictions'] \n",
    "flat_list = [float('%.1f'%(item)) for sublist in results for item in sublist]\n",
    "print('predictions: \\t{}'.format(np.array(flat_list)))\n",
    "print('target values: \\t{}'.format(y_test[:10].round(decimals=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the AWS Step Functions Data Science SDK, there are many other workflows you can create to automate your machine learning tasks.  For example, you could create a workflow to automate model retraining on a periodic basis.  Such a workflow could include a test of model quality after training, with subsequent branches for failing (no model deployment) and passing the quality test (model is deployed).  Other possible workflow steps include Automatic Model Tuning, data preprocessing with AWS Glue, and more.  \n",
    "\n",
    "For a detailed example of a retraining workflow, see the AWS ML Blog post [Automating model retraining and deployment using the AWS Step Functions Data Science SDK for Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/automating-model-retraining-and-deployment-using-the-aws-step-functions-data-science-sdk-for-amazon-sagemaker/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup <a class=\"anchor\" id=\"Cleanup\">\n",
    "\n",
    "The workflow we created above deployed a model to an endpoint.  To avoid billing charges for an unused endpoint, you can delete it using the SageMaker console.  To do so, go to the [SageMaker console](https://console.aws.amazon.com/sagemaker/).  Then click **Endpoints** in the left panel, and select and delete any unneeded endpoints in the list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(tuning_predictor.endpoint_name)\n",
    "sess.delete_endpoint(workflow_predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions <a class=\"anchor\" id=\"Extensions\">\n",
    "\n",
    "We've covered a lot of content in this notebook:  SageMaker Processing for data transformation, Local Mode for prototyping training and inference code, Automatic Model Tuning, and SageMaker hosted training and inference.  These are central elements for most deep learning workflows in SageMaker.  Additionally, we examined how the AWS Step Functions Data Science SDK helps automate deep learning workflows after completion of the prototyping phase of a project.\n",
    "\n",
    "Besides all of the SageMaker features explored above, there are many other features that may be applicable to your project.  For example, to handle common problems during deep learning model training such as vanishing or exploding gradients, **SageMaker Debugger** is useful.  To manage common problems such as data drift after a model is in production, **SageMaker Model Monitor** can be applied."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
